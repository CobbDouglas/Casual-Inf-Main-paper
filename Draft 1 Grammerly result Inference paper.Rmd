---
title: "Draft 1 Causal Inference Paper"
author: "Daniel Ownby"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Introduction

In 2023, it has been estimated that at least 58.7 million adults in the United States had some sort of mental illness. In the same year, 14.6 million were estimated to have a serious mental illness that resulted in serious functional impairment or interfered with at least one or more major life activities. Only 66.7% of those 14.6 million received any mental health treatment in the past year. According to the Centers for Disease Control's (CDC) WISQARS Leading Causes of Death Report, Suicides are the second leading cause of death amongst people aged 10-34 and are ranked as the 11th overall. Suicide rates have gradually increased over the past two decades, starting with 10.5 per 100,000 people to 14.2 per 10,000 in 2018. Suicide rates vary from state to state with both east and west coasts supporting low rates such as 7.4 per 100,000 while mid-western states suffer from rates as high as 25 per 100,000. This within-state variation typically is not a problem for modern economists using two-way fixed effects. More recently in the econometrics literature, more attention has been given to the problem of dynamic timing of federal policies and the potential bias it might bring to traditional two-way fixed effects. In this paper, I attempt to replicate \@lang2013 findings of the effects of the Mental Health Parity Act of 1996 using \@sun2021, \@callaway2021, and \@goodman-bacon2021 as a way to estimate the average treatment effect while deconstructing the two-way fixed effect regression. Additionally, I use several propensity score measures to compare to newer methods. I find that traditional methods are in line with previous results while dynamic timing methods estimate somewhere at 3% or 5% depending on the method and base period used. [\@klick2006; \@centers]

Lang (2013)

\@lang2013 attempts to identify causal effects using difference-in-difference methods and fixed effects using policy shocks resulting from the aftereffects of the Federal Health Parity Act of 1996. \@lang2013 showed a statistically significant effect of a 4-7% decrease in suicide rate after policy implementation using two-way fixed effects. To do this with the rollout of policies from the states, \@lang2013 set 1998 as \$t_0\$ since most were enacted afterward. I draw the same data detailed in the study while using more modern statistical methods that surround difference in differences. I run my difference in difference using regression similar to \@lang2013 in addition to conducting propensity score matching methods to achieve a better balance between covariates between control and treatment states. I also used more dynamic difference-in-difference methods using the data and found similar results as the preliminary difference in difference and Two-way Fixed Effects.

Mental Health Parity Act

In 1996, Congress pushed forward legislation, sponsored by Senator Pete V. Domenici, to address rising concerns about mental health and how insurers treat those with mental health issues. The aim of the Federal Mental Health Parity Act of 1996 was to provide equal treatment of regular physical services and psychological services. With the MHPA, Congress banned group insurance plans that have a lower annual or lifetime dollar cap for mental health services if they offered mental health services. However, subsequent reports from the General Accounting Office (GAO) concerning the MHPA put into question whether or not the federal law had any effect. \@GAO2000 While firms were complying with the letter of the law, the law itself was narrow enough that insurers could offset costs by limiting mental health services through several avenues known as Quantitative Treatment Limits. According to the survey the GAO conducted, most employers began offering mental health plans that were more restrictive with in-treatment stays with mental health services than regular treatment. Others offered one or two more unique plans and designs that were as equally restrictive. While disappointing results for federal lawmakers, Most states in 2002 instated mental health parity laws alongside further stipulations with varying degrees of restrictiveness and exemptions. [\@samsha2023; \@GAO2000]

Parity laws:

Any state implementing a law that requires insurance packages to include access to mental health services and to have those services at parity with any other physical service is flagged as a parity state. This type of law is the strongest type among the ones implemented and is the type expected to create an effect this study investigates. A less strict version of the parity law is the "mandated offering" law, which does not force insurance package providers to provide mental health services in the first place. This can be a crucial difference when it comes to further analysis but for the purposes of this study, both are lumped together as a Parity state.

Data

My data set pulls from the same sources from \@lang2013 with the exception of one variable. The data set is a sample of 15 years from 1990 to 2004 in 50 states including the District of Columbia. In total, the entire matrix is 765 observations. I have 6 main variables, the first of which is the main outcome variable logged crude suicide rate. I pull from the CDC WONDER database \@centers for the compressed mortality statistics. Both queries included anything that was labeled intentional self-harm fatalities in both ICD-9 and ICD-10. The same database also contained crude population statistics for each state in that given year. The Unemployment rate was obtained through The Current Population Survey. Bankruptcy statistics were obtained through the US bankruptcy court tables converted into Excel data and coded from the available population statistics. Percent Workers from large firms variable was created from the County Business Patterns Survey obtained through the US census website.

Further variables were hand-coded for the analysis. Information regarding the policy status of states during which years was taken from the appendix of \@lang2013. Binary variables were created that denoted the status of a parity or non-parity law in place including the type of parity law enacted. Lastly, I created a variable that denoted the exact year where a parity law was enacted for each state which serves as a grouping variable for the \@callaway2021 analysis.

Summary Statistics

Table 1 details the weighted averages for the data set. The crude rate of suicides per 100k of the population was 11.32. The weighted mean log suicide rate was 2.4. The mean unemployment rate was 5.6. Mean bankruptcies per 100k is 436. The mean percent of workers in large firms in the data is 48%.

Table 2 subsets the data into 3 categories, Pre-Parity, Post-Parity, and No-Parity group. In the pre-parity group, the suicide rate was 10.85 while the post-parity suicide rate decreased to 9.84. The No-Parity Group had a weighted average of 12.57 throughout the data set's time period.

\@lang2013 Simple Difference in Differences

Table 3 replicates the summary statistics found in \@lang2013 and uses the \@lang2013 method of implementing the difference in difference intervention in the year 1998. Here the weighted mean suicide rates of the pre and post-treatment group are 11.08 and 9.8 respectively. The pre and post-control group weighted means additionally stand at 12.89 and 12.43. Table 4 displays the weighted mean log suicide rates in a similar fashion.

Table 5 Introduces the simple difference-in-differences design that is explored in \@lang2013. Both panels are averages weighted by state populations that denote pre and post-group cutoff between the two periods of 1990-1997 and 1998-2004. Standard errors are reported in parenthesis and in brackets are the number of observations that fall in this group. \@lang2013 uses this specification to conduct the analysis for the rest of his regressions. I replicate the main Difference in Difference results in both panels with a slightly higher Panel A result at -.65 per 100k decrease in suicides and a Panel B result at a similar 8%. Both are significant at the same levels in \@lang2013 Table 3.

My Difference in Difference

For the rest of this analysis, I will not be using the intervention timing assumption cut-off in order to conduct the rest of the regressions. All groups in the regressions after this point are accurate to the year they were implemented. That is to say, while \@lang2013 had to treat treated states as if they were passed in 1998 in order for the difference-in-difference framework to function, I am afforded the liberty of using the dynamic difference-in-difference. Additionally, I've excluded things included in \@lang2013 due to the author stating they had no impact on the main results. These include a lagged suicide rate timing control and dropping observations of states that passed a parity law in the middle of the year. Table 4 Column 2 also dropped observations so that only states that eventually become treated are left. I replicated this column with the data included and found no difference in the investigated effect.

Replicating Lang 2013

\$\$

Suicide\_{st}= \\alpha +\\beta\_{1}Access\_{st}+\\beta\_{2}NonParityLaw\_{st}+\\delta X\_{st}+\\gamma\_{s}+\\pi_t +\\varepsilon\_{st}

\\tag{1}

\$\$

I used the typical panel approach in all the subsequent analyses unless stated otherwise. My dependent variable is denoted by \$Suicide\_{st}\$ which is the log crude suicide rate per 100,000 people in the state \$s\$ and year \$t\$. The \$Access\_{st}\$ term denotes an Access to Parity Law in effect over the state \$s\$ and time period \$t\$. \$NonParityLaw\_{st}\$ term denotes a non-parity law, either a is in effect at state \$s\$ and year \$t\$. \$X\_{st}\$ denotes unemployment, bankruptcy, and large firm controls. The \$\\gamma\_{s}\$ and \$\\pi\_{t}\$ are the state and yearly fixed effects respectively.

\*Explain Access to parity and Non-Parity Law

TWFE, MATCHING and Heterogeneous Treatment Effects

TWFE

Table 6 details a replication of Table 4 of \@lang2013. Regressing the log suicide rate, The first column returns a similar estimate to the first column of Table 4 in \@lang2013. I find a 4.2% decrease in the suicide rate compared to \@lang2013 5% for Access to Parity states. The second column replicates the same column in \@lang2013 finding another 4% reduction. We chose not to reduce our sample size for this column since both regressions report the same coefficient. Column (3) distinguishes itself from the rest of the regressions as the only model that loses the significance of the main variable and does not replicate from \@lang2013. Column (3) of Table 6 also shows Mandated offering laws significant for a 9% decrease in the log suicide rate compared to \@lang2013 12%. Column (4) continues with the Access to Parity variable significant at the 5% level with a coefficient of 4.6% compared with \@lang2013 7%. Overall, I see a similar or reduced magnitude in the estimated effect.

Matching

Our first extension to \@lang2013 uses the assumption of a 1998 treatment time from \@lang2013 and adds matching to the difference in difference model as a robustness check. I run several different matching methods available to the \@MatchIt package.

Tables 7, 8, and 9 detail Difference-in-Differences regressions using two-way fixed effects. The same as previous models, variables are weighted by population at that state's point in time and additionally are clustered at the state level. Columns 1 and 2 detail the Difference in Difference models using Mahalanobis distance, switching between the regular and logged suicide rate. Columns 3 and 4 show models matched with a probit method. The only significant effect was found in column 4 with a -4% decrease associated with the post-treatment effect. Table 8 features GLM in columns 1 and 2 with the only significant effect belonging to column 2, finding the same coefficient as Table 7 Column 4. Columns 3 and 4 showcase models with Cardinality matching and find no significant effects. Table 9 Uses Coarse-Exact matching and Subclass matching to find the same coefficient in column 4. Overall every matching method that either cut down on the observations or didn't use a logged crude rate did not retrieve significant effects.

Dynamic treatment Effects

The second extension to \@lang2013 I bring is a dive into Dynamic treatment effects using both \@sun2021 and \@callaway2021 to see if a roll-out design can capture the same effects found in the previous regressions. Here we can evaluate the effect on each state's access to parity policy without worrying about introducing contamination through comparisons of past and future treated units. I will first Introduce the \@sun2021 results compare them with \@callaway2021 results and complete the discussion with the \@goodman-bacon2021 decomposition.

Interaction-weighted estimates (Sun and Abraham 2021)

Table 10 displays the results of 3 models run with varying base periods. All regressions use the parity law group variable that tracks the first year of each policy implementation. The first model with a base period of -1 does not return a significant ATT when evaluating parity law policy. The second column does return a significant effect of a 3% decrease in suicides with a base period of -2. The third column follows a suggestion of dropping the first year of the data set from \@sun2021 to add more control units, resulting in a similar 3% decrease in suicides.

Difference in Difference with Multiple Time Periods (Callaway and Sant'Anna)

Table 11 contains the estimates for \@callaway2021. All regressions use the parity law group timing discussed in the last section. Columns 1, 2, and 4 arrive at similar estimates of a 5% decrease in suicides, the first two using the universal base period while Column 3 uses a varying base period. In column 4, I experimented with setting different anticipation periods and saw results at a significant 3% decrease in suicides with the anticipation setting at -1.

Goodman-Bacon

Figure 2 shows the results of the \@goodman-bacon2021 decomposition graph breakdown of the weights involved in a Two-way Fixed Effects Regression on the log suicide rate without population weighting. From the graph we can show that most of the treated vs untreated comparisons make up most of the weight on the ATT, only 30% of comparisons made consist of those "forbidden" comparisons of early vs later treated that can introduce contaminated results. The ATT estimated was -1.35%.

Conclusion

My findings concur with the findings of the seminal paper \@lang2013 and estimate a negative 3-5% effect on suicides. Borrowing from \@lang2013 back of the hand math, 29 states had a suicide rate of 10.24 and a total population of 160 221 455. A decrease of 3% to 5% would save between 492 to 820 lives nationally per year. The mechanism behind the results was the political shock resulting from passing the Mental Health Parity Act of 1996. As explained in \@harrison2002, the passing of the MHPA created state incentives to pass their own version of mental health parity law to bypass federal oversight. This is due to a provision in the law that, so long the state fulfills the minimum requirements, states retain the authority to regulate parity laws. This resulted in the wave of states implementing parity laws afterward.

One of the main limitations of this study revolves around the 1 in 10 rule for judging how many controls can a model handle before the model is in danger of overfitting. In the case of the regular two-way fixed effects, we have 3 main controls while we have 66 total state and year controls with a \$n\$ of 765 resulting in a rough ratio of 11 observations per control. This is pretty close to the acceptable line. For the newer methods, we have a total of 112 controls, for a cohort of 8 treatment years multiplied by the 14 years taken into consideration, dropping the first year of each cohort. This results in a ratio of roughly 7 observations per control, firmly below the rule of thumb. This and a combination of some cohorts having less than 30 observations causes logistic regression used by \@callaway2021 and their doubly robust methods return blown-up standard errors and missing values.

Policy implications are straightforward. Stronger, more restrictive laws that provide means towards healthcare utilization make for a stronger suicide rate reduction. The more services offered by insurers, the more treatment people get. If full parity granted in 29 states resulted in a national 5% reduction in the suicide rate even for just two years as the research implies, it's worth pursuing politically. Newer research using quality microdata would be a powerful way of working with the question of the effectiveness of mental health parity. Papers like \@ortega2023, which study Medicaid expansion while using dynamic differences-in-differences, are a great framework using modern data with modern statistics. Future research should focus on the new 2024 Federal Parity rules that the Biden administration has implemented to combat non-quantitative treatment limitations that insurers use to limit utilization.
